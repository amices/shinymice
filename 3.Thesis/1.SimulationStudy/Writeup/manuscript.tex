% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  Royal, times, sageapa]{sagej}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Missing the Point: Detecting Non-Convergence in Multiple Imputation Procedures},
  pdfauthor={Hanne I. Oberman},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

\title{Missing the Point: Detecting Non-Convergence in Multiple Imputation
Procedures}
\author{Hanne I. Oberman}
\date{16-3-2020}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

At some point, any scientist conducting statistical analyses will run
into a missing data problem (Allison 2001). Missingness is problematic
because statistical inference cannot be performed on incomplete data
without employing \emph{ad hoc} solutions (e.g., list-wise deletion),
which may yield wildly invalid results (Van Buuren 2018). A popular
answer to the ubiquitous problem of missing information is to use the
framework of multiple imputation (MI), proposed by Rubin (1987). For the
theoretical foundation of MI, see Rubin (1987). For an accessible and
comprehensive introduction to MI from an applied perspective, see
e.g.~Van Buuren (2018). With MI, missing datapoints are `imputed' (i.e.,
filled in) via an \emph{imputation model}. The imputation model can be a
joint model for all variables, or several univariate conditional
distributions (fully conditional specification). FCS is more flexible
and ``avoids the problem of specifying an appropriate joint imputation
distribution and replaces this by the selection of appropriate
univariate conditional distributions''. With FCS, an iterative
algorithmic procedure is used to \ldots{} multiple imputation by chained
equations \ldots{} ``The values for imputing the missing data are drawn
from the posterior predictive distribution of the missing data
conditional on the observed data.'' There is no scientific consensus on
the convergence properties of FCS algorithms (Takahashi 2017). Some
default techniques in \texttt{mice} might not yield converged states at
all (Murray 2018). Therefore, algorithmic convergence should be
monitored carefully.

Convergence cannot be determined for sure, because MICE is an MCMC
method, and convergence of MCMC is not from scalar to a point, but from
one distribution to another. Generated values will vary even after
convergence. Therefore we can only diagnose non-convergence, not
convergence (Hoff 2009). ``a weak diagnostics is better than no
diagnostic at all'' (Cowles and Carlin 1996).

Current practice is visually inspecting imputation chains for signs of
non-convergence, but may be challenging to the untrained eye (Van Buuren
2018, \(\S\) 6.5.2). Therefore diagnostic evaluation of convergence
would be preferred. However, not known whether MCMC diagnostics are
appropriate for MICE \ldots{} The application of convergence diagnostics
to MI methods has not been systematically studied (Van Buuren 2018). How
can non-convergence be diagnosed? How many iterations are
sufficient/required? What are the effects of non-convergence on
estimates, predictions and inference? What is an appropriate
non-convergence diagnostic? Are the default number of iterations
sufficient? Defaults in: SPSS = 10
\href{https://www.ibm.com/support/knowledgecenter/SSLVMB_24.0.0/spss/mva/syn_multiple_imputation_impute.html}{(link)},
Mplus = 100??
\href{https://pdfs.semanticscholar.org/e20e/29e008592cbfbaa567931f74cdfdb5451405.pdf?_ga=2.55354671.54033656.1584698748-527613517.1584698748}{(link)},
Stata = 1;
\href{https://www.stata.com/manuals13/mi.pdf,\%20p.\%20139}{(link)},
Amelia = NA, because resampling, not convergence
\href{https://cran.r-project.org/web/packages/Amelia/Amelia.pdf}{(link)},
en MI = 30
\href{https://cran.r-project.org/web/packages/mi/mi.pdf}{(link)}.

For reasons of brevity, we only focus on the MI algorithm implemented in
the world-leading MI software: the \texttt{R} (R Core Team 2019) package
\texttt{mice} (Van Buuren and Groothuis-Oudshoorn 2011). The convergence
properties of this MI algorithm are investigated through model-based
simulation. The results of this simulation study are guidelines for
assessing convergence of MI algorithms, which will aid applied
researchers in drawing valid inference from incomplete datasets.

\hypertarget{notation}{%
\subsection{Notation}\label{notation}}

Let \(y\) denote an \(n \times p\) matrix containing the data values on
\(p\) variables for all \(n\) units in a sample. The data value of unit
\(i\) (\(i = 1, \dots, n\)) on variable \(j\) (\(j = 1, \dots, p\)) may
be either observed or missing. The collection of observed data values in
\(y\) is denoted by \(y_{obs}\); the missing part of \(y\) is referred
to as \(y_{mis}\). For each datapoint in \(y_{mis}\) \(M \times T\)
times plausible values are sampled, where \(M\) is the number of
imputations (\(m = 1, \dots, M\)) and \(T\) is the number of iterations
(\(t = 1, \dots, T\)). The collection of samples between the initial
value (at \(t=1\)) and the imputed value (at \(t=T\)) will be referred
to as an `imputation chain'.

\hypertarget{convergence-diagnostics}{%
\section{Convergence diagnostics}\label{convergence-diagnostics}}

In iterative algorithmic procedures (Markov chain Monte Carlo methods;
e.g., \texttt{mice} algorithms or Gibbs samplers) non-convergence may be
present as non-stationarity within chains (i.e., trending), or as slow
mixing between chains (i.e., no intermingling). (\textbf{add
example/guidelines visual inspection here?})

The stationarity component of convergence may be evaluated with
autocorrelation (\(AC\); Schafer 1997; Gelman et al. 2013), numeric
standard error (or `MC error'; Geweke 1992), and Raftery and Lewis's
(1991) procedure to determine the effect of trending within chains.

The mixing component can be assessed with the potential scale reduction
factor \(\widehat{R}\) (a.k.a. `Gelman-Rubin statistic'; Gelman and
Rubin 1992). With an adapted version of \(\widehat{R}\), proposed by
Vehtari et al. (2019), we might also evaluate the stationarity component
of convergence. This would make \(\widehat{R}\) a general convergence
diagnostic. The application of \(\widehat{R}\) to assess stationarity
has not been thoroughly investigated. Therefore, this study employs both
\(\widehat{R}\) and autocorrelation to investigate convergence, as
recommended by (Cowles and Carlin 1996, 898).

Note that all of these methods evaluate the convergence of univariate
scalar summaries (e.g., chain means or variances). These convergence
diagnostics cannot diagnose convergence of multivariable statistics
(i.e., relations between scalar summaries). Van Buuren (2018) proposed
to implement multivariable evaluation through eigenvalue decomposition
(MacKay and Mac Kay 2003). This method is outside of the scope of the
current study (\textbf{not anymore!}).

\hypertarget{potential-scale-reduction-factor}{%
\subsection{Potential scale reduction
factor}\label{potential-scale-reduction-factor}}

To define \(\widehat{R}\), we follow notation by (Vehtari et al. 2019,
5). Let \(M\) be the total number of chains, \(T\) the number of
iterations per chain, and \(\theta\) the scalar summary of interest
(e.g., chain mean or chain variance). For each chain
(\(m = 1, 2, \dots, M\)), we estimate the variance of \(\theta\), and
average these to obtain within-chain variance \(W\).

\begin{align*}
W&=\frac{1}{M} \sum_{m=1}^{M} s_{j}^{2},  \text { where } s_{m}^{2}=\frac{1}{T-1} \sum_{t=1}^{T}\left(\theta^{(t m)}-\bar{\theta}^{(\cdot m)}\right)^{2}. 
\end{align*}

We then estimate between-chain variance \(B\) as the variance of the
collection of average \(\theta\) per chain.

\begin{align*}
B&=\frac{T}{M-1} \sum_{m=1}^{M}\left(\bar{\theta}^{(\cdot m)}-\bar{\theta}^{(\cdot \cdot)}\right)^{2}, \text { where } \bar{\theta}^{(\cdot m)}=\frac{1}{T} \sum_{t=1}^{T} \theta^{(t m)}, \quad \bar{\theta}^{(\cdot \cdot)}=\frac{1}{M} \sum_{m=1}^{M} \bar{\theta}^{(\cdot m)}. 
\end{align*}

From the between- and within-chain variances we compute a weighted
average, \(\widehat{\operatorname{var}}^{+}\), which over-estimates the
total variance of \(\theta\). \(\widehat{R}\) is then obtained as a
ratio between the over-estimated total variance and the within-chain
variance:

\begin{equation*}
\widehat{R}=\sqrt{\frac{\widehat{\operatorname{var}}^{+}(\theta | y)}{W}},
\text{ where } \widehat{\operatorname{var}}^{+}(\theta | y)=\frac{N-1}{N} W+\frac{1}{N} B.
\end{equation*}

We can interpret \(\widehat{R}\) as potential scale reduction factor
since it indicates by how much the variance of \(\theta\) could be
shrunken down if an infinite number of iterations per chain would be run
(Gelman and Rubin 1992). This interpretation assumes that chains are
`over-dispersed' at \(t=1\), and reach convergence as \(T \to \infty\).
Over-dispersion implies that the initial values of the chains are `far
away' from the target distribution and each other. When all chains
sample independent of their initial values, the mixing component of
convergence is satisfied, and \(\widehat{R}\)-values will be close to
one. High \(\widehat{R}\)-values thus indicate non-convergence. The
conventionally acceptable threshold for convergence was
\(\widehat{R} < 1.2\) (Gelman and Rubin 1992). More recently, Vehtari et
al. (2019) proposed a more stringent threshold of
\(\widehat{R} < 1.01\).

\hypertarget{autocorrelation}{%
\subsection{Autocorrelation}\label{autocorrelation}}

Following the same notation, we define autocorrelation as the
correlation between two subsequent \(\theta\)-values within the same
chain (Lynch 2007, 147). In this study we only consider \(AC\) at lag 1,
i.e., the correlation between the \(t^{th}\) and \(t+1^{th}\) iteration
of the same chain.

\begin{equation*}
AC = \left( \frac{T}{T-1} \right) \frac{\sum_{t=1}^{T-1}(\theta_t - \bar{\theta}^{(\cdot m)})(\theta_{t+1} - \bar{\theta}^{(\cdot m)})}{\sum_{t=1}^{T}(\theta_t - \bar{\theta}^{(\cdot m)})^2}.
\end{equation*}

We can interpret \(AC\)-values as a measure of stationarity. If
\(AC\)-values are close to zero, there is no dependence between
subsequent samples within imputation chains. Positive \(AC\)-values,
however, indicate recurrence. If \(\theta\)-values of subsequent
iterations are similar, trending may occur. Negative \(AC\)-values show
no threat to the stationarity component of convergence. On the contrary
even---negative \(AC\)-values indicate that \(\theta\)-values of
subsequent iterations diverge from one-another, which may increase the
variance of \(\theta\) and speed up convergence. As convergence
diagnostic, the interest is therefore in positive \(AC\)-values.
Moreover, the magnitude of \(AC\)-values may be evaluated statistically,
but that is outside of this note's scope.

In short, convergence is reached when there is no dependency between
subsequent iterations of imputation chains (\(AC = 0\)), and chains
intermingle such that the only difference between the chains is caused
by the randomness induced by the algorithm (\(\widehat{R} = 1\)).

\hypertarget{simulation-hypothesis}{%
\subsection{Simulation Hypothesis}\label{simulation-hypothesis}}

This study evaluates whether \(\widehat{R}\) and \(AC\) could diagnose
convergence of multiple imputation algorithms. We assess the performance
of the two convergence diagnostics against the recommended evaluation
criteria for MI methods (i.e., average bias, average confidence interval
width, and empirical coverage rate across simulations; Van Buuren 2018,
\(\S\) 2.5.2). That is, there is no baseline measure available to
evaluate performance against.The current practice of visually inspecting
imputation chains for signs of non-mixing or non-stationarity can only
diagnose severely pathological cases of non-convergence. We could also
look at distributional characteristics, and plausibility of imputed
values, see Vink (n.d.). For now, this is outside of the scope of this
study.

Based on an empirical finding (Lacerda, Ardington, and Leibbrandt 2007),
we hypothesize that \(\widehat{R}\) will over-estimate non-convergence
of MI algorithms. The threshold of \(\widehat{R} < 1.01\) will then be
too stringent for diagnosing convergence. This over-estimation may,
however, be diminished because \(\widehat{R}\) can falsely diagnose
convergence if initial values of the algorithm are not appropriately
over-dispersed (Brooks and Gelman 1998, 437). In \texttt{mice}, initial
values are chosen randomly from the observed data. Therefore, we cannot
be certain that the initial values are over-dispersed. We expect this to
have little effect on the hypothesized performance of \(\widehat{R}\).
No hypothesis was formulated about the performance of \(AC\) as
convergence diagnostic.

\hypertarget{simulation-study}{%
\section{Simulation study}\label{simulation-study}}

The convergence of \texttt{mice} is investigated through model-based
simulation in \texttt{R} (version 3.6.3; R Core Team 2019). The
simulation set-up is summarized in the pseudo-code below. The complete
\texttt{R} script of the simulation study is available from
\href{https://github.com/gerkovink/shinyMice/tree/master/3.Thesis/1.SimulationStudy}{github.com/gerkovink/shinyMice}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# pseudo-code of simulation }
\NormalTok{simulate data }
\ControlFlowTok{for}\NormalTok{ (number of simulation runs from }\DecValTok{1}\NormalTok{ to }\DecValTok{1000}\NormalTok{)}
  \ControlFlowTok{for}\NormalTok{ (number of iterations from }\DecValTok{1}\NormalTok{ to }\DecValTok{100}\NormalTok{)}
\NormalTok{    create missingness}
\NormalTok{    impute the missingness}
\NormalTok{    compute convergence diagnostics}
\NormalTok{    perform analysis}
\NormalTok{    pool results}
\NormalTok{    compute simulation diagnostics}
\NormalTok{aggregate convergence and simulation diagnostics}
\end{Highlighting}
\end{Shaded}

A finite population of \(N=1000\) is simulated to solve a multiple
linear regression problem, where dependent variable \(Y\) is regressed
on independent variables \(X_1\), \(X_2\) and \(X_3\):

\[Y \sim \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3.\]

The data generating model is a multivariate normal distribution

\begin{align*}
\begin{pmatrix}X_1\\
X_2\\
X_3\\
\epsilon
\end{pmatrix} \sim  N
\begin{bmatrix}
\begin{pmatrix}
12\\
3\\
0.5\\
0
\end{pmatrix}\!\!,
\begin{pmatrix}
4 & 4 & 1.8 & 0\\
4 & 16 & 4.8 & 0\\
1.8 & 4.8 & 9 & 0\\
0 & 0 & 0 & 100
\end{pmatrix}
\end{bmatrix}\\[2\jot]
\end{align*}

and simulated with the function \texttt{mvtnorm::rmvnorm()}. Outcome
variable \(Y\) is subsequently calculated as
\[Y =  2X_1 + .5X_2 - X_3 + \epsilon .\]

The complete data is `amputed' once for each simulation repetition. That
is, the function \texttt{mice::ampute()} is used to impose a missingness
mechanism upon the data. \textbf{(change this: The missingness is
univariate, and the probability to be missing is the same for all four
variables, namely 20\% (\texttt{prop\ =\ 0.8,\ mech\ =\ "MCAR"}). This
leaves 20\% of the rows completely observed). }

Missing datapoints are imputed with the function \texttt{mice::mice()}.
All MI procedures are performed with Bayesian linear regression
imputation (\texttt{method\ =\ "norm"}), and five imputation chains
(\texttt{m\ =\ 5}). The number of iterations varies between simulation
conditions (\texttt{maxit\ =\ 1,\ 2,\ \textbackslash{}dots,\ 100}).

\textbf{(tot hier doorgelezen)}

What to evaluate?

\begin{itemize}
\item
  bias in regression coefficients
\item
  bias in \(R^2\) (= coefficient of determination)
\item
\end{itemize}

\(\widehat{R}\) is computed by implementing Vehtari et al.'s (2019)
recommendations. \(AC\) is computed with function \texttt{stats::acf()}.

To estimate the quantity of scientific interest, \(Q\), we perform
multiple linear regression on each completed dataset with the function
\texttt{stats::lm()}. We obtain an estimated regression coefficient per
imputation, which are pooled into a single estimate, \(\bar{Q}\). We use
the function \texttt{mice::pool()} to get variance estimates according
to Rubin's (1987) rules, and subsequently implement finite population
pooling conform Vink and Buuren (2014).

We compute bias as the difference between \(\bar{Q}\) and \(Q\).
Confidence interval width (CIW) is defined as the difference between the
lower and upper bound of the 95\% confidence interval (CI95\%) around
\(\bar{Q}\). We compute the CI95\% bounds as

\[\bar{Q} \pm t_{(m-1)} \times SE_{\bar{Q}},\]

where \(t_{(m-1)}\) is the quantile of a \(t\)-distribution with \(m-1\)
degrees of freedom, and \(SE_{\bar{Q}}\) is the square root of the
pooled variance estimate. From bias and CIW, we calculate empirical
coverage rates. Coverage rate is the proportion of simulations in which
\(Q\) is between the bounds of the CI95\% around \(\bar{Q}\).

\hypertarget{results}{%
\section{Results}\label{results}}

Feedback:

\begin{itemize}
\tightlist
\item
  Add more info about figure legends and axes.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# plot results}
\KeywordTok{load}\NormalTok{(}\StringTok{"../Results/results.Rdata"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{convergence-diagnostics-1}{%
\subsection{Convergence Diagnostics}\label{convergence-diagnostics-1}}

It is apparent that there is a relation between the number of iterations
per simulation condition (\(T\)) and the convergence diagnostics.
Generally speaking, conditions with longer imputation chains (higher
\(T\)) coincide with less signs of non-convergence
(\(\widehat{R}\)-values approach one, and \(AC\)-values approach zero).
We see more or less equivalent trends for chain means versus chain
variances. We, therefore, only discuss the \(\widehat{R}\) and
\(AC\)-values of chain means.

Figure 2A shows that \(\widehat{R}\)-values generally decrease with
increasing imputation chain lengths. The decline stabilizes somewhere
between the simulation conditions \(T=30\) and \(T=50\). The downward
trend is most pronounced for \(T=3\), and between \(T = 5\) and
\(T = 10\). In the intervening conditions (\(3 \leq T \leq 5\)),
however, we observe a steep increase in \(\widehat{R}\)-values. This
increase implies that non-convergence is under-estimated, and
convergence should not be diagnosed at this point. Based on the
conventional threshold \(\widehat{R} < 1.2\), we would falsely diagnose
convergence at \(T=3\). According to the widely used threshold
\(\widehat{R} < 1.1\), convergence would be diagnosed for conditions
where \(T>9\). If we use the recently recommended threshold
\(\widehat{R} < 1.01\), we would conclude that convergence is reached in
none of the simulation conditions.

The \(AC\)-values displayed in Figure 2B are almost uniformly increasing
as a function of \(T\). The only \(AC\)-value that deviates from this
observation is for \(T=2\). The lowest \(AC\)-value is obtained for
\(T=3\). \%At \(T=5\), the \(AC\)-value reaches the level observed at
\(T=2\). The gradual increase plateaus between \(T=10\) and \(T=30\).
\(AC\)-values in conditions where \(T>70\) are indifferentiable from
zero, indicating stationarity. We see an initial decrease between
\(T=2\) and \(T=3\). Simulation conditions where \(T>5\) have
\(AC\)-values greater than \(T=2\).

According to this diagnostic, none of the simulation conditions show
signs of non-convergence, since we only observe negative or zero
\(AC\)-values. The negative \(AC\)-values, however, indicate increasing
divergence between subsequent samples in conditions where \(T<4\). It
may not be wise to terminating the algorithm at that point, but after
`recovering' from this dip in \(AC\)-values. This would imply \(T=6\) as
the minimal number of iterations.

Taken together, we see that \(T>3\) is the minimal requirement to
diagnose convergence (\(\widehat{R} < 1.2; AC \leq 0\)). This threshold
is, however, not sufficient, since we overlook the increase in
\(\widehat{R}\)-values up-to conditions where \(T>5\), and the
convergence diagnostics only reach stability at \(T>20\).

\hypertarget{simulation-diagnostics}{%
\subsection{Simulation Diagnostics}\label{simulation-diagnostics}}

We use average bias, average confidence interval width, and coverage
rate as performance measures to evaluate \(\widehat{R}\) and \(AC\). We
make the general observation that the simulation diagnostics behave as
theorized for most simulation conditions (bias around zero, stable
confidence interval widths, nominal coverage rate at 95\%).

Figure 3A shows that bias is fairly stable across simulation conditions.
The condition \(T=1\) clearly deviates from this trend with a negative
bias. The bias for \(T=2\) is below average, but within the range of
fluctuations. Conditions where \(T>3\) can be diagnosed as unbiased, but
the average bias across iterations (as shown by a flat Loess line) only
reaches stability at \(T=20\).

CIW is only clearly divergent in the simulation condition \(T=1\), see
Figure 3B. However, under-estimating the variance of \(\bar{Q}\), which
is the case for \(T=3\), may yield spurious inferences. Only conditions
where \(T>3\) are therefore considered sufficient. These conditions have
similar CIWs, but across iterations stability is not established (i.e.,
the Loess line is never completely flat within the 100 simulation
conditions). \%After about twenty-five iterations the average CIW across
all simulation conditions and repetitions is reached 0.927.

The empirical coverage rate across repetitions seems more or less stable
for conditions where \(T>1\), see Figure 3C. We see some over-coverage
at \(T=2\), but that is better than under-estimating the variance of
\(\bar{Q}\). On average, the coverage rate is somewhat higher than the
expected nominal coverage of 95\% (Neyman 1934), namely 95\%. Similar to
the CIWs, there is some trending across iterations (i.e., the Loess line
is never flat).

From the simulation diagnostics, we observe that unbiased estimates with
nominal coverage rates were obtained in conditions where \(T>3\). This
suggests that as little as four iterations may be sufficient for the MI
algorithm under the current circumstances.

In short, there is a discrepancy between what the convergence
diagnostics and what the performance measures indicate. While \(T=4\)
seems sufficient with respect to simulation quantities, the condition
where \(T=4\) resulted in the `one-but-worst' values of both convergence
diagnostics. Complete algorithmic convergence as indicated by
\(\widehat{R}\) and autocorrelation is not reached in conditions where
\(T<20\).

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

This note shows that convergence diagnostics \(\widehat{R}\) and \(AC\)
may diagnose convergence of multiple imputation algorithms, but their
performance differs from conventional applications to iterative
algorithmic procedures.\\
\(\widehat{R}\) and autocorrelation indicate that algorithmic
convergence may only be reached after twenty or even forty iterations,
while unbiased, confidence valid estimates estimates may be obtained
with as little as four iterations. These results are in agreement with
the simulation hypothesis: \(\widehat{R}\) over-estimates the severity
of non-convergence when applied to MI procedures. \%This may be due to
the quantity of scientific interest chosen. More `complicated' \(Q\)s
(e.g., higher order effects or variance components) might show bias,
under- or over-coverage at higher \(T\).

According to this simulation study, the recently proposed threshold of
\(\widehat{R}<1.01\) may be too stringent for MI algorithms. Under the
relatively easy missing data problem of the current study, the threshold
was not reached. The other extreme of the \(\widehat{R}\)-thresholds,
the conventionally acceptable \(\widehat{R} <1.2\), may be too lenient
for MI procedures. Applying this threshold to the current data, lead to
falsely diagnosing convergence at \(T = 3\). It appears that the widely
used threshold of \(\widehat{R} < 1.1\) suits MI algorithms the best. We
might, however, also formulate a new threshold, specifically for the
evaluation of MI algorithms. The current study suggests that
\(\widehat{R} < 1.05\) may be implemented, since that is the level at
which the \(\widehat{R}\) stabilize (around \(T = 20\)).

The negative \(AC\)-values obtained in this study show no threat of
non-stationarity. However, initial dip in \(AC\)-values may have
implications for the default number of iterations in \texttt{mice}
(\texttt{maxit\ =\ 5}). Terminating the algorithm at \(T=5\) may not be
the most appropriate, since this lead to the worst convergence, as
indicated by \(\widehat{R}\) and \(AC\). Under the current
specifications, \(T>20\) would be more appropriate.

The observed dip in AC implies that default maxit value of five
iterations is the worst possible number of iterations. Moreover, the
results of this study imply that assessing the stationarity component of
convergence with \(AC\) might be redundant, since high \(AC\)-values are
implausible in MI procedures. That is, the randomness induced by the MI
algorithm effectively mitigates the risk of dependency within chains.
\(AC\) would thus not be informative of the convergence of MI
algorithms.

Since this study only considers only an MCAR missingness mechanism,
results may not be extrapolated to other missing data problems. Proper
performance of the convergence diagnostics under MCAR is necessary but
not sufficient to demonstrate appropriateness of \(\widehat{R}\) and
\(AC\) as convergence diagnostics. This is just a proof of concept.

Further research is needed to investigate their performance under clear
violation of convergence, e.g.~dependency between predictors (predictors
with very high correlations). Until then, we have only shown that the
convergence diagnostics can diagnose non-convergence of MI algorithms
that trend towards a converged state. Also for future research,
implement Wernicke diagnostic, and look at developing a convergence
diagnostic for substantive models, and implement a Wald test for
\(AC = 0\).

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-alli02}{}%
Allison, Paul D. 2001. \emph{Missing Data}. Sage publications.

\leavevmode\hypertarget{ref-broo98}{}%
Brooks, Stephen P., and Andrew Gelman. 1998. ``General Methods for
Monitoring Convergence of Iterative Simulations.'' \emph{Journal of
Computational and Graphical Statistics} 7 (4): 434--55.
\url{https://doi.org/10.1080/10618600.1998.10474787}.

\leavevmode\hypertarget{ref-cowl96}{}%
Cowles, Mary Kathryn, and Bradley P Carlin. 1996. ``Markov Chain Monte
Carlo Convergence Diagnostics: A Comparative Review.'' \emph{Journal of
the American Statistical Association} 91 (434): 883--904.

\leavevmode\hypertarget{ref-gelm13}{}%
Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki
Vehtari, and Donald B. Rubin. 2013. \emph{Bayesian Data Analysis}.
Philadelphia, PA, United States: CRC Press LLC.

\leavevmode\hypertarget{ref-gelm92}{}%
Gelman, Andrew, and Donald B. Rubin. 1992. ``Inference from Iterative
Simulation Using Multiple Sequences.'' \emph{Statistical Science} 7 (4):
457--72. \url{https://doi.org/10.1214/ss/1177011136}.

\leavevmode\hypertarget{ref-gewe92}{}%
Geweke, John. 1992. ``Evaluating the Accuracy of Sampling-Based
Approaches to the Calculations of Posterior Moments.'' \emph{Bayesian
Statistics} 4: 641--49.

\leavevmode\hypertarget{ref-hoff09}{}%
Hoff, Peter D. 2009. \emph{A First Course in Bayesian Statistical
Methods}. Springer Texts in Statistics. New York, NY: Springer New York.
\url{https://doi.org/10.1007/978-0-387-92407-6}.

\leavevmode\hypertarget{ref-lace07}{}%
Lacerda, Miguel, Cally Ardington, and Murray Leibbrandt. 2007.
``Sequential Regression Multiple Imputation for Incomplete Multivariate
Data Using Markov Chain Monte Carlo.'' University of Cape Town, South
Africa.

\leavevmode\hypertarget{ref-lync07}{}%
Lynch, Scott M. 2007. \emph{Introduction to Applied Bayesian Statistics
and Estimation for Social Scientists}. Springer Science \& Business
Media.

\leavevmode\hypertarget{ref-mack03}{}%
MacKay, David JC, and David JC Mac Kay. 2003. \emph{Information Theory,
Inference and Learning Algorithms}. Cambridge university press.

\leavevmode\hypertarget{ref-murr18}{}%
Murray, Jared S. 2018. ``Multiple Imputation: A Review of Practical and
Theoretical Findings.'' \emph{Statistical Science} 33 (2): 142--59.
\url{https://doi.org/10.1214/18-STS644}.

\leavevmode\hypertarget{ref-neym34}{}%
Neyman, Jerzy. 1934. ``On the Two Different Aspects of the
Representative Method: The Method of Stratified Sampling and the Method
of Purposive Selection.'' \emph{Journal of the Royal Statistical
Society} 97 (4): 558--625. \url{https://doi.org/10.2307/2342192}.

\leavevmode\hypertarget{ref-raft91}{}%
Raftery, Adrian E, and Steven Lewis. 1991. ``How Many Iterations in the
Gibbs Sampler?'' Washington University Seatle, Department of Statistics,
United States.

\leavevmode\hypertarget{ref-R}{}%
R Core Team. 2019. \emph{R: A Language and Environment for Statistical
Computing}. Vienna, Austria. \url{https://www.R-project.org/}.

\leavevmode\hypertarget{ref-rubin87}{}%
Rubin, Donald B. 1987. \emph{Multiple Imputation for Nonresponse in
Surveys}. Wiley Series in Probability and Mathematical Statistics
Applied Probability and Statistics. New York, NY: Wiley.

\leavevmode\hypertarget{ref-scha97}{}%
Schafer, Joseph L. 1997. \emph{Analysis of Incomplete Multivariate
Data}. Chapman; Hall/CRC.

\leavevmode\hypertarget{ref-taka17}{}%
Takahashi, Masayoshi. 2017. ``Statistical Inference in Missing Data by
MCMC and Non-MCMC Multiple Imputation Algorithms: Assessing the Effects
of Between-Imputation Iterations.'' \emph{Data Science Journal} 16
(July): 37. \url{https://doi.org/10.5334/dsj-2017-037}.

\leavevmode\hypertarget{ref-buur18}{}%
Van Buuren, Stef. 2018. \emph{Flexible Imputation of Missing Data}.
Chapman; Hall/CRC.

\leavevmode\hypertarget{ref-mice}{}%
Van Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011. ``Mice:
Multivariate Imputation by Chained Equations in R.'' \emph{Journal of
Statistical Software} 45 (1): 1--67.
\url{https://doi.org/10.18637/jss.v045.i03}.

\leavevmode\hypertarget{ref-veht19}{}%
Vehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and
Paul-Christian BÃ¼rkner. 2019. ``Rank-Normalization, Folding, and
Localization: An Improved \$\textbackslash widehat\{R\}\$ for Assessing
Convergence of MCMC,'' March. \url{http://arxiv.org/abs/1903.08008}.

\leavevmode\hypertarget{ref-vinknd}{}%
Vink, Gerko. n.d. ``Towards a Standardized Evaluation of Multiple
Imputation Routines.''

\leavevmode\hypertarget{ref-vink14}{}%
Vink, Gerko, and Stef van Buuren. 2014. ``Pooling Multiple Imputations
When the Sample Happens to Be the Population.'' \emph{arXiv:1409.8542
{[}Math, Stat{]}}, September. \url{http://arxiv.org/abs/1409.8542}.

\end{document}
